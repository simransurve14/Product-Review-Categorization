{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80ce4d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# loading the sentiment analysis model\n",
    "sentiment_label_map={'positive': 0, 'negative': 1, 'neutral': 2}\n",
    "sentiment_model=TFAutoModelForSequenceClassification.from_pretrained(\"sentiment_analysis/sentiment_results\", num_labels=len(sentiment_label_map),from_pt=True)\n",
    "sentiment_tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
    "\n",
    "#loading the categorization model\n",
    "categorization_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "categorization_label_map={'quality': 0, 'overall': 1, 'service': 2, 'price': 3}\n",
    "categorization_model=TFAutoModelForSequenceClassification.from_pretrained(\"results\", num_labels=len(categorization_label_map),from_pt=True)\n",
    "\n",
    "#loading the sarcasm detecion model\n",
    "sarcasm_tokenizer = AutoTokenizer.from_pretrained(\"nikesh66/Sarcasm-Detection-using-BERT\")\n",
    "sarcasm_label_map={'sarcasm': 0, 'not sarcasm': 1}\n",
    "sarcasm_model = TFAutoModelForSequenceClassification.from_pretrained(\"sarcasm_detection\\sarcasm_results\", num_labels=len(sarcasm_label_map),from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0739e83e-7778-449a-9495-37511d1bf683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(review,sentiment_tokenizer,sentiment_model,sentiment_label_map):\n",
    "    # Tokenize the user review (assuming you have a tokenizer)\n",
    "    tokenized_user_review = sentiment_tokenizer(review, truncation=True, padding=True, return_tensors=\"tf\")\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = sentiment_model.predict(dict(tokenized_user_review))\n",
    "\n",
    "    # Extract the predicted probabilities for each class\n",
    "    predicted_probabilities = predictions[0][0]\n",
    "\n",
    "    # Get the predicted class index\n",
    "    predicted_class_index = predicted_probabilities.argmax()\n",
    "\n",
    "    def print_key_by_value(dict, value1):\n",
    "      for key, value in dict.items():\n",
    "        if value == value1:\n",
    "          return key\n",
    "\n",
    "    # Example usage:\n",
    "    predicted_category=print_key_by_value(sentiment_label_map,predicted_class_index )\n",
    "    # Print the predicted class index\n",
    "    return predicted_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95bf3ace-9ae0-4ab9-935e-f3f45d4a6da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(review,categorization_tokenizer,categorization_model,categorization_label_map):\n",
    "# Tokenize the user review (assuming you have a tokenizer)\n",
    "    tokenized_user_review = categorization_tokenizer(review, truncation=True, padding=True, return_tensors=\"tf\")\n",
    "\n",
    "# Make predictions\n",
    "    predictions = categorization_model.predict(dict(tokenized_user_review))\n",
    "\n",
    "# Extract the predicted probabilities for each class\n",
    "    predicted_probabilities = predictions[0][0]\n",
    "\n",
    "# Get the predicted class index\n",
    "    predicted_class_index = predicted_probabilities.argmax()\n",
    "\n",
    "    def print_key_by_value(dict, value1):\n",
    "      for key, value in dict.items():\n",
    "        if value == value1:\n",
    "          return key\n",
    "\n",
    "# Example usage:\n",
    "    predicted_category=print_key_by_value(categorization_label_map,predicted_class_index )\n",
    "# Print the predicted class index\n",
    "    #print('predicted index',predicted_class_index)\n",
    "    return predicted_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6494fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarcasm_detection(review,sarcasm_tokenizer,sarcasm_model,sarcasm_label_map):\n",
    "    # Tokenize the user review (assuming you have a tokenizer)\n",
    "    tokenized_user_review = sarcasm_tokenizer(review, truncation=True, padding=True, return_tensors=\"tf\")\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = sarcasm_model.predict(dict(tokenized_user_review))\n",
    "\n",
    "    # Extract the predicted probabilities for each class\n",
    "    predicted_probabilities = predictions[0][0]\n",
    "\n",
    "    # Get the predicted class index\n",
    "    predicted_class_index = predicted_probabilities.argmax()\n",
    "\n",
    "    def print_key_by_value(dict, value1):\n",
    "      for key, value in dict.items():\n",
    "        if value == value1:\n",
    "          return key\n",
    "\n",
    "    # Example usage:\n",
    "    predicted_category=print_key_by_value(sarcasm_label_map,predicted_class_index )\n",
    "    # Print the predicted class index\n",
    "    return predicted_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48132fbb-ba91-42e8-9b7c-d9cc248ece7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = input('enter review:')\n",
    "print(sentiment_analysis(input_text,sentiment_tokenizer,sentiment_model,sentiment_label_map))\n",
    "print(categorize(input_text,categorization_tokenizer,categorization_model,categorization_label_map))\n",
    "print(sarcasm_detection(input_text,sarcasm_tokenizer,sarcasm_model,sarcasm_label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8557ce9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 1s 869ms/step\n",
      "1/1 [==============================] - 1s 700ms/step\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def sentiment_and_category(review):\n",
    "    sentiment = sentiment_analysis(review,sentiment_tokenizer,sentiment_model,sentiment_label_map)\n",
    "    category = categorize(review,categorization_tokenizer,categorization_model,categorization_label_map)\n",
    "    sarcasm = sarcasm_detection(review,sarcasm_tokenizer,sarcasm_model,sarcasm_label_map)\n",
    "    if sarcasm=='sarcasm':\n",
    "        sentiment1='negative'\n",
    "    else:\n",
    "        sentiment1=sentiment\n",
    "    return sentiment1, category\n",
    "\n",
    "\n",
    "iface = gr.Interface(fn=sentiment_and_category, \n",
    "                     inputs=\"text\", \n",
    "                     outputs=[gr.Textbox(label=\"Sentiment\", lines=3),gr.Textbox(label=\"Category\", lines=3)], \n",
    "                     title=\"Product Review Categorization and Sentiment Analysis\",\n",
    "                     description=\"Enter your product review below and get sentiment and category analysis.\")\n",
    "\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009029f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
